# 논문 요약

이 논문은 전장 환경에서의 경로계획 문제를 다루며, 기존의 장애물 회피 중심의 경로계획과 달리 장애물을 은폐와 엄폐에 활용하는 전략적 인공전위장(SAPF)과 Q-learning을 결합한 Q-SAPF 알고리즘을 제안한다. 연구의 주요 내용은 다음과 같다.

## 연구 배경 및 목적
- 전장 환경에서는 장애물을 단순히 피하는 것이 아니라, 적의 탐지와 공격을 회피하기 위해 적극적으로 활용해야 한다.
- 최근 유무인 복합체계(MUM-T) 등 다양한 군사작전에서 경로계획의 중요성이 커지고 있으며, 지상·공중·해상 등 다양한 환경에서의 적용이 요구된다.
- 본 연구는 지상 전장환경에서 다양한 지형(평지, 언덕, 건물, 숲, 강 등)을 고려하여 은폐와 엄폐가 가능한 경로를 탐색하는 방법을 제시한다.

## 관련 연구
- 기존 경로계획 연구는 A*, DQN, APF 등 다양한 방법을 활용해왔으나, 대부분 장애물 회피에 초점을 맞춤.
- APF는 목표점에 대한 인력과 장애물에 대한 반발력을 이용해 경로를 생성하지만, 전장 환경의 특수성을 반영하기에는 한계가 있다.
- Q-learning은 환경에 대한 사전 지식 없이 시행착오를 통해 최적 정책을 학습하는 강화학습 기법으로, 경로계획 문제에 효과적으로 적용될 수 있다.
- UAV, USV 등 다양한 무인 시스템의 경로계획 연구가 활발히 이루어지고 있으며, 복잡한 환경에서의 실시간 경로계획, 장애물 회피, 에너지 효율성 등이 주요 이슈로 다뤄진다.

## 제안 방법
- SAPF(Strategic Artificial Potential Field)는 기존 APF와 달리 장애물에도 인력을 부여하여, 장애물을 피하는 것이 아니라 은폐·엄폐에 활용할 수 있도록 설계됨. 목표점과 장애물 각각에 대해 인력 계수를 다르게 적용하여, 목표점 도달을 우선시하면서도 장애물 근처를 활용하는 경로를 유도함.
- Q-SAPF는 SAPF로 탐색한 경로를 기반으로 Q-learning을 적용한다. SAPF로 초기 경로를 탐색한 뒤, Q-learning을 통해 시행착오 기반의 정책 학습을 수행하여 경로의 효율성과 성공률을 높임. Q-learning은 상태-행동 가치(Q-table)를 학습하며, 보상은 경로 성공, 장애물 회피, 목표 도달 등에 따라 차등 부여됨.
- 실험 환경은 50x50 격자 지도와 다양한 지형 코드(평지, 언덕, 파괴/비파괴 건물, 숲, 강, 도로 등)로 구성되며, 실제 한반도 DMZ 인근 지형을 모사한 8개의 맵을 사용함. 각 맵은 지형 분포가 다르며, 다양한 장애물과 은폐/엄폐 지형이 혼재되어 있음.

## 실험 및 결과
- 네 가지 방법(APF, SAPF, Q-learning, Q-SAPF)을 동일 환경에서 반복 실험하여 경로 길이, 경로 점수(지형 특성 및 은폐/엄폐 반영), 실험 시간, 성공률을 비교함.
- 경로 점수는 지형별로 점수를 부여(예: 언덕, 숲, 파괴 가능한 건물 등은 +점수, 이동이 불리한 지형은 -점수, 통과 불가 장애물은 0점)하고, 은폐·엄폐가 가능한 경로에 추가 점수를 부여함.
- Q-SAPF는 전반적으로 가장 짧은 경로, 높은 경로 점수, 짧은 실험 시간, 높은 성공률을 기록함. 특히 Q-SAPF는 모든 맵에서 99% 이상의 성공률을 보였으며, Q-learning 대비 경로 길이와 시간, 점수에서 모두 우수함을 보임.
- 통계적 유의성 검증(ANOVA, 사후분석, Friedman test) 결과, Q-SAPF의 성능 우위가 통계적으로 유의함이 확인됨. 각 맵별로도 Q-SAPF가 일관되게 최상위 랭크를 기록함.
- APF와 SAPF는 장애물 분포에 따라 경로가 길어지거나, 진동(oscillation) 현상으로 인해 비효율적인 경로가 생성되는 한계가 있었음. Q-learning은 시행착오 기반으로 경로를 찾지만, 장애물 활용 측면에서 Q-SAPF에 비해 성능이 낮았음.

## 주요 실험 테이블별 요약

### 1. 실험 결과 요약 테이블 (Table 9)
- 8개 맵에서 APF, SAPF, Q-learning, Q-SAPF 네 가지 방법의 경로 길이, 경로 점수, 실험 시간, 성공률을 비교.
- Q-SAPF는 모든 맵에서 가장 짧은 경로(최대 80칸 이상 차이), 높은 경로 점수, 짧은 시간, 99% 이상의 성공률을 기록.
- Q-learning 대비 Q-SAPF는 경로 길이와 시간, 점수에서 모두 우수하며, APF/SAPF 대비 진동 현상 없이 효율적 경로를 탐색함.

### 2. 분산분석(ANOVA) 및 사후분석 테이블 (Table 10~25) 상세 요약
- 각 맵별로 경로 길이, 경로 점수, 실험 시간, 성공률에 대해 네 가지 방법(APF, SAPF, Q-learning, Q-SAPF)의 평균 차이를 분산분석(ANOVA)으로 검정함.
- 모든 맵, 모든 지표에서 p<0.05로 통계적으로 유의한 차이가 존재함을 확인.

#### (1) 경로 길이
- Q-SAPF가 APF, SAPF, Q-learning 대비 유의하게 더 짧은 경로를 생성함.
- 예시: Map 1에서 Q-SAPF는 APF 대비 약 61.9, SAPF 대비 41.7, Q-learning 대비 11.5만큼 경로가 짧음.
- 모든 맵에서 Q-SAPF의 경로 길이 우위가 통계적으로 유의함.

#### (2) 경로 점수
- Q-SAPF는 Q-learning 대비 경로 점수가 높고, APF/SAPF는 진동 현상 등으로 점수가 높게 나오는 경우도 있으나 실제 효율성은 낮음.
- 예시: Map 2에서 Q-SAPF의 점수는 Q-learning 대비 37.8점 높음.
- 사후분석에서 Q-SAPF와 Q-learning 간 점수 차이가 유의함(p<0.05).

#### (3) 실험 시간
- Q-SAPF가 APF, SAPF, Q-learning 대비 경로 탐색 시간이 가장 짧음.
- 예시: Map 2에서 Q-SAPF는 APF 대비 11.4초, SAPF 대비 250.5초, Q-learning 대비 69.7초 더 빠름.
- 모든 맵에서 Q-SAPF의 시간 우위가 통계적으로 유의함.

#### (4) 성공률
- Q-SAPF는 모든 맵에서 99% 이상의 성공률을 기록, Q-learning은 맵에 따라 40~80%대로 변동.
- 예시: Map 3에서 Q-SAPF는 Q-learning 대비 31.5%p, APF 대비 41.4%p, SAPF 대비 97.0%p 더 높음.
- 사후분석에서 Q-SAPF의 성공률이 다른 모든 방법 대비 유의하게 높음(p<0.05).

- 결론적으로, 분산분석 및 사후분석 결과 Q-SAPF가 모든 지표에서 기존 방법 대비 통계적으로 유의하게 우수함이 입증됨.

### 3. 맵별 종합 결과 테이블 (Table 26~29)
- Table 26: 맵별 경로 길이 비교. Q-SAPF가 모든 맵에서 가장 짧은 경로를 보임.
- Table 27: 맵별 경로 점수 비교. Q-SAPF가 Q-learning 대비 점수가 높고, APF/SAPF는 진동으로 인해 점수가 높게 나오는 경우도 있으나 실제 효율성은 낮음.
- Table 28: 맵별 실험 시간 비교. Q-SAPF가 가장 짧은 시간에 경로를 탐색함.
- Table 29: 맵별 성공률 비교. Q-SAPF는 모든 맵에서 99% 이상의 성공률을 기록, Q-learning은 맵에 따라 40~80%대로 변동.

### 4. Friedman Test 순위 테이블 (Table 30)
- 각 맵, 각 지표별로 Q-SAPF가 일관되게 1위(최상위) 랭크를 기록.
- 통계적으로도 Q-SAPF의 우수성이 검증됨.

## 실험 결과 종합
- Q-SAPF는 모든 실험 맵에서 경로 길이, 점수, 시간, 성공률 등 모든 지표에서 기존 방법 대비 우수함을 보임.
- 특히 복잡한 장애물 분포, 다양한 지형에서도 일관된 성능을 유지하며, 실험적·통계적으로도 그 효과가 입증됨.
- 기존 APF/SAPF의 진동 문제, Q-learning의 장애물 활용 한계를 극복한 점이 특징임.

---

## [용어 설명] 분산분석(ANOVA)와 사후분석이란?

- **분산분석(ANOVA, Analysis of Variance)**
  - 여러 집단(여기서는 APF, SAPF, Q-learning, Q-SAPF)의 평균값이 통계적으로 유의하게 차이가 있는지 검정하는 통계 기법입니다.
  - 예를 들어, 네 가지 알고리즘의 경로 길이 평균이 서로 다른지, 단순한 우연이 아닌 실제 차이가 있는지 확인할 때 사용합니다.
  - p값이 0.05 미만이면 “적어도 한 집단의 평균이 다르다”고 결론 내릴 수 있습니다.

- **사후분석(Post-hoc Test)**
  - 분산분석에서 유의미한 차이가 발견된 경우, 어떤 집단끼리 차이가 나는지 구체적으로 비교하는 추가 분석입니다.
  - 본 논문에서는 Tukey HSD(가장 널리 쓰이는 사후분석 방법 중 하나)를 사용하여, 예를 들어 Q-SAPF와 Q-learning, APF, SAPF 각각의 평균 차이가 통계적으로 유의한지 확인했습니다.
  - 이를 통해 “Q-SAPF가 다른 모든 방법보다 경로 길이가 짧다”와 같은 구체적 결론을 도출할 수 있습니다.
